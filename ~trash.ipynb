{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd0519ba696b20d93792fe8c5eef783bc1c7f089152001e8956e74a5d1b2f43e031",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from util import pickle_dump, pickle_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GEAGY    has duplicate date index\tduplicate dates: ['2021-04-08']\n",
      "~trash   has duplicate date index\tduplicate dates: ['2021-04-01' '2021-04-08']\n",
      "\n",
      "symbols with duplicate date index: ['GEAGY', '~trash']\n"
     ]
    }
   ],
   "source": [
    "dir_path = 'C:/Users/ping/Google Drive/stocks/MktCap2b_AUMtop1200/OHLCV/'\n",
    "col_names = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "symbols_duplicate_dates = []\n",
    "symbols = ['XOM', 'AAPL', 'GEAGY', 'Z', '~trash']\n",
    "for symbol in symbols:\n",
    "    df = pd.read_csv(dir_path + symbol + \".csv\", names=col_names, parse_dates=True, index_col=0)\n",
    "    idx_duplicates = df.index.duplicated()  # return array [False False False ... True False True]\n",
    "    idx_duplicates_True = np.where(idx_duplicates)[0]  # locations where values are True\n",
    "    if idx_duplicates_True.size != 0:  # df has duplicate dates\n",
    "        date_duplicates = df.index[idx_duplicates_True].values  # duplicate dates in format ['2021-04-08T00:00:00.000000000']\n",
    "        date_duplicates = np.array(date_duplicates, dtype='datetime64[D]')  # change to format ['2021-04-01']\n",
    "        symbols_duplicate_dates.append(symbol)\n",
    "        print(f'{symbol:8} has duplicate date index\\tduplicate dates: {date_duplicates}')\n",
    "print(f'\\nsymbols with duplicate date index: {symbols_duplicate_dates}') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['2021-04-01' '2021-04-08'] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "tmp_date = np.array(date_duplicates, dtype='datetime64[D]')\n",
    "print(tmp_date, type(tmp_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'C:/Users/ping/Google Drive/stocks/MktCap2b_AUMtop1200/OHLCV/'\n",
    "col_names = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "symbols_duplicate_dates = []\n",
    "symbols = ['XOM', 'AAPL', 'GEAGY', 'Z']\n",
    "for symbol in symbols:\n",
    "    df = pd.read_csv(dir_path + symbol + \".csv\", names=col_names, parse_dates=True, index_col=0,)\n",
    "    idx_duplicates = df.index.duplicated()\n",
    "    if any(idx_duplicates) == True:\n",
    "        print('symbol with duplicate index: {}, index_duplicates: {}'.format(symbol, idx_duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_num = len(l_close) / 2\n",
    "int_mid_num = int(mid_num)\n",
    "l_close_1 = l_close[0:int_mid_num]\n",
    "l_close_2 = l_close[int_mid_num::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_temp = 'C:/Users/ping/Google Drive/stocks/MktCap2b_AUMtop1200/VSCode_dump/'\n",
    "l_close = pickle_load(path_temp, 'trash_l_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int_mid_num, len(l_close), len(l_close_1), len(l_close_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(l_close_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat(l_close_1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat(l_close_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}